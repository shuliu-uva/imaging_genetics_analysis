{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load global and regional structural data\n",
    "import pandas as pd\n",
    "\n",
    "# my data file path\n",
    "data = pd.read_csv('/data/sliu/updated_ukbb2/raw_data/matched_ukbb.csv')\n",
    "\n",
    "# the items of global structural measures\n",
    "total_items = pd.read_csv('/data/sliu/updated_ukbb2/raw_data/total_items.csv')\n",
    "s1 = ['karin_IDs']\n",
    "for i in range(total_items.shape[0]):\n",
    "    s1.append(str(total_items.iloc[i,0])+'-2.0')\n",
    "\n",
    "# the items of regional structural measures\n",
    "regional_items = pd.read_csv('/data/sliu/updated_ukbb2/raw_data/regional_items_no_volumes.csv')\n",
    "s2 = ['karin_IDs']\n",
    "for i in range(regional_items.shape[0]):\n",
    "    s2.append(str(regional_items.iloc[i,0])+'-2.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/sliu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/data/sliu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# total brain measures (total CSA, average CT and ICV)\n",
    "T_data = data[s1]\n",
    "T_data.dropna(axis=0,how='any',inplace=True)\n",
    "\n",
    "# regional brain measures (CSA, CT based on DKT atlas)\n",
    "R_data = data[s2]\n",
    "R_data.dropna(axis=0,how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/sliu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: FutureWarning: read_table is deprecated, use read_csv instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# load covariates (age, sex, head positions, the top 25 principal components)\n",
    "temp = pd.read_csv('/data/sliu/updated_ukbb/added_used_variables.csv')\n",
    "s = ['eid','25756-2.0','25757-2.0','25758-2.0']\n",
    "QC1 = temp[s]\n",
    "temp2 = pd.read_csv('/data/sliu/muti_PRSs/ukb30545.sample_QC.csv')\n",
    "s2 = ['eid','age_at_reqruitment','genetic_sex']\n",
    "QC2 = temp2[s2]\n",
    "PCs = pd.read_table('/data/sliu/muti_PRSs/UKB.HM3.EUR.100PCs.txt','\\t')\n",
    "\n",
    "# load Polygenic scores for 14 mental health and cognitive traits\n",
    "PRS_data = pd.read_csv('/data/sliu/updated_ukbb/ukb_PRSs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matching subject IDs\n",
    "T_data.set_index('karin_IDs', inplace=True)\n",
    "R_data.set_index('karin_IDs', inplace=True)\n",
    "QC1.set_index('eid',inplace=True)\n",
    "QC2.set_index('eid',inplace=True)\n",
    "PCs.set_index('IID',inplace=True)\n",
    "PRS_data.set_index('FID',inplace=True)\n",
    "l = list(set(T_data.index) & set(R_data.index) & set(QC1.index) & set(QC2.index) & set(PCs.index) & set(PRS_data.index))\n",
    "final_Ts = T_data.loc[l]\n",
    "final_Rs = R_data.loc[l]\n",
    "final_QC1 = QC1.loc[l]\n",
    "final_QC2 = QC2.loc[l]\n",
    "final_PCs = PCs.loc[l]\n",
    "final_PRSs = PRS_data.loc[l]\n",
    "\n",
    "final_Ts.reset_index(inplace=True)\n",
    "final_Rs.reset_index(inplace=True)\n",
    "final_QC1.reset_index(inplace=True)\n",
    "final_QC2.reset_index(inplace=True)\n",
    "final_PCs.reset_index(inplace=True)\n",
    "final_PRSs.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge covariates together \n",
    "import numpy as np\n",
    "PCs_25 = final_PCs.iloc[:,2:27].values\n",
    "age = final_QC2.iloc[:,1:2].values\n",
    "sex = final_QC2.iloc[:,2:3].values\n",
    "postions = final_QC1.iloc[:,1:4].values\n",
    "TA = (final_Ts.iloc[:,1:2].values + final_Ts.iloc[:,2:3].values)/2\n",
    "AT = (final_Ts.iloc[:,3:4].values + final_Ts.iloc[:,4:5].values)/2\n",
    "ICV = final_Ts.iloc[:,5:6].values\n",
    "sex = sex + 1\n",
    "co1 = np.hstack((PCs_25,age,sex,age*age,age*sex,age*age*sex,postions,TA)) # for CSA analysis\n",
    "co2 = np.hstack((PCs_25,age,sex,age*age,age*sex,age*age*sex,postions,AT)) # for CT analysis\n",
    "co3 = np.hstack((PCs_25,age,sex,age*age,age*sex,age*age*sex,postions,ICV)) # for analysis of subcortical volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare structural data\n",
    "area_items = pd.read_csv('/data/sliu/updated_ukbb2/raw_data/area_items.csv')\n",
    "thickness_items = pd.read_csv('/data/sliu/updated_ukbb2/raw_data/thickness_items.csv')\n",
    "volume_items = pd.read_csv('/data/sliu/updated_ukbb2/raw_data/sub_items.csv')\n",
    "area_s = []\n",
    "for i in range(area_items.shape[0]):\n",
    "    area_s.append(str(area_items.iloc[i,0])+'-2.0')\n",
    "thickness_s = []\n",
    "for i in range(thickness_items.shape[0]):\n",
    "    thickness_s.append(str(thickness_items.iloc[i,0])+'-2.0')\n",
    "volume_s = []\n",
    "for i in range(volume_items.shape[0]):\n",
    "    volume_s.append(str(volume_items.iloc[i,0])+'-2.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SA_data = final_Rs[area_s].values\n",
    "CT_data = final_Rs[thickness_s].values\n",
    "volume_data = final_Rs[volume_s].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function used for regressing out the effects of covariates \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def regression_covariant(covariant_matrix, y, standard_scale=False):\n",
    "    a = np.hstack((covariant_matrix,np.ones((covariant_matrix.shape[0], 1))))\n",
    "    w = np.linalg.lstsq(a,y,rcond=None)[0]\n",
    "\n",
    "    residual = y - covariant_matrix.dot(w[:-1])\n",
    "    residual = residual.astype('float64')\n",
    "\n",
    "    if standard_scale:\n",
    "        residual = StandardScaler().fit_transform(residual.reshape(-1,1)).flatten()\n",
    "\n",
    "    return residual, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson's correlation analysis between PRSs and CSA\n",
    "from scipy.stats import pearsonr\n",
    "X = final_PRSs.iloc[:,1:].values\n",
    "X[:,7] = -X[:,7]\n",
    "X[:,8] = -X[:,8]\n",
    "X[:,11] = -X[:,11]\n",
    "Y = SA_data\n",
    "SA_R = np.empty((X.shape[1],Y.shape[1]))\n",
    "SA_P = np.empty((X.shape[1],Y.shape[1]))\n",
    "for i in range(X.shape[1]):\n",
    "    for j in range(Y.shape[1]):\n",
    "        x = X[:,i]\n",
    "        y = Y[:,j]\n",
    "        [rx,w1] = regression_covariant(co1,x,standard_scale=True)\n",
    "        [ry,w1] = regression_covariant(co1,y,standard_scale=True)\n",
    "        r,p = pearsonr(rx, ry)\n",
    "        SA_R[i,j] = r\n",
    "        SA_P[i,j] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson's correlation analysis between PRSs and CT\n",
    "Y = CT_data\n",
    "CT_R = np.empty((X.shape[1],Y.shape[1]))\n",
    "CT_P = np.empty((X.shape[1],Y.shape[1]))\n",
    "for i in range(X.shape[1]):\n",
    "    for j in range(Y.shape[1]):\n",
    "        x = X[:,i]\n",
    "        y = Y[:,j]\n",
    "        [rx,w1] = regression_covariant(co2,x,standard_scale=True)\n",
    "        [ry,w1] = regression_covariant(co2,y,standard_scale=True)\n",
    "        r,p = pearsonr(rx, ry)\n",
    "        CT_R[i,j] = r\n",
    "        CT_P[i,j] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson's correlation analysis between PRSs and subcortical volumes\n",
    "Y = volume_data\n",
    "volume_R = np.empty((X.shape[1],Y.shape[1]))\n",
    "volume_P = np.empty((X.shape[1],Y.shape[1]))\n",
    "for i in range(X.shape[1]):\n",
    "    for j in range(Y.shape[1]):\n",
    "        x = X[:,i]\n",
    "        y = Y[:,j]\n",
    "        [rx,w1] = regression_covariant(co3,x,standard_scale=True)\n",
    "        [ry,w1] = regression_covariant(co3,y,standard_scale=True)\n",
    "        r,p = pearsonr(rx, ry)\n",
    "        volume_R[i,j] = r\n",
    "        volume_P[i,j] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge their results (P values) together\n",
    "total_P = np.hstack((SA_P,CT_P,volume_P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FDR multiple comparison correction\n",
    "from statsmodels.stats import multitest\n",
    "size = total_P.shape\n",
    "temp_p = total_P.flatten()\n",
    "Ps = multitest.multipletests(temp_p,alpha=0.05,method='fdr_bh')\n",
    "P_corrected = Ps[1].reshape(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_num = 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "SA_P_corrected = P_corrected[:,:2*region_num]\n",
    "CT_P_corrected = P_corrected[:,2*region_num:4*region_num]\n",
    "volume_P_corrected = P_corrected[:,4*region_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output CSA results\n",
    "lSA_R = SA_R[:,:region_num]\n",
    "lSA_P = SA_P[:,:region_num]\n",
    "lSA_P_corrected = SA_P_corrected[:,:region_num]\n",
    "re_l_R = pd.DataFrame(data=lSA_R)\n",
    "re_l_R.to_csv('/data/sliu/updated_ukbb2/regional_results2/area_left_R.csv',header=None,index=False)\n",
    "re_l_P = pd.DataFrame(data=lSA_P)\n",
    "re_l_P.to_csv('/data/sliu/updated_ukbb2/regional_results2/area_left_P.csv',header=None,index=False)\n",
    "re_l_P_corrected = pd.DataFrame(data=lSA_P_corrected)\n",
    "re_l_P_corrected.to_csv('/data/sliu/updated_ukbb2/regional_results2/area_left_P_corrected.csv',header=None,index=False)\n",
    "\n",
    "rSA_R = SA_R[:,region_num:]\n",
    "rSA_P = SA_P[:,region_num:]\n",
    "rSA_P_corrected = SA_P_corrected[:,region_num:]\n",
    "re_r_R = pd.DataFrame(data=rSA_R)\n",
    "re_r_R.to_csv('/data/sliu/updated_ukbb2/regional_results2/area_right_R.csv',header=None,index=False)\n",
    "re_r_P = pd.DataFrame(data=rSA_P)\n",
    "re_r_P.to_csv('/data/sliu/updated_ukbb2/regional_results2/area_right_P.csv',header=None,index=False)\n",
    "re_r_P_corrected = pd.DataFrame(data=rSA_P_corrected)\n",
    "re_r_P_corrected.to_csv('/data/sliu/updated_ukbb2/regional_results2/area_right_P_corrected.csv',header=None,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output CT results\n",
    "lCT_R = CT_R[:,:region_num]\n",
    "lCT_P = CT_P[:,:region_num]\n",
    "lCT_P_corrected = CT_P_corrected[:,:region_num]\n",
    "re_l_R = pd.DataFrame(data=lCT_R)\n",
    "re_l_R.to_csv('/data/sliu/updated_ukbb2/regional_results2/thickness_left_R.csv',header=None,index=False)\n",
    "re_l_P = pd.DataFrame(data=lCT_P)\n",
    "re_l_P.to_csv('/data/sliu/updated_ukbb2/regional_results2/thickness_left_P.csv',header=None,index=False)\n",
    "re_l_P_corrected = pd.DataFrame(data=lCT_P_corrected)\n",
    "re_l_P_corrected.to_csv('/data/sliu/updated_ukbb2/regional_results2/thickness_left_P_corrected.csv',\\\n",
    "                        header=None,index=False)\n",
    "\n",
    "rCT_R = CT_R[:,region_num:]\n",
    "rCT_P = CT_P[:,region_num:]\n",
    "rCT_P_corrected = CT_P_corrected[:,region_num:]\n",
    "re_r_R = pd.DataFrame(data=rCT_R)\n",
    "re_r_R.to_csv('/data/sliu/updated_ukbb2/regional_results2/thickness_right_R.csv',header=None,index=False)\n",
    "re_r_P = pd.DataFrame(data=rCT_P)\n",
    "re_r_P.to_csv('/data/sliu/updated_ukbb2/regional_results2/thickness_right_P.csv',header=None,index=False)\n",
    "re_r_P_corrected = pd.DataFrame(data=rCT_P_corrected)\n",
    "re_r_P_corrected.to_csv('/data/sliu/updated_ukbb2/regional_results2/thickness_right_P_corrected.csv',\\\n",
    "                        header=None,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output results of subcortical volumes \n",
    "subvol_R = volume_R\n",
    "subvol_P = volume_P\n",
    "subvol_P_corrected = volume_P_corrected\n",
    "re_sub_R = pd.DataFrame(data=subvol_R)\n",
    "re_sub_R.to_csv('/data/sliu/updated_ukbb2/regional_results2/volume_sub_R.csv',header=None,index=False)\n",
    "re_sub_P = pd.DataFrame(data=subvol_P)\n",
    "re_sub_P.to_csv('/data/sliu/updated_ukbb2/regional_results2/volume_sub_P.csv',header=None,index=False)\n",
    "re_sub_P_corrected = pd.DataFrame(data=subvol_P_corrected)\n",
    "re_sub_P_corrected.to_csv('/data/sliu/updated_ukbb2/regional_results2/volume_sub_P_corrected.csv',header=None,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
